# Unified Policy Framework

í†µí•© ì •ì±… í”„ë ˆì„ì›Œí¬ëŠ” LeRobotê³¼ GR00T N1ì˜ ë‹¤ì–‘í•œ ì •ì±…ë“¤(ACT, Diffusion, Pi0, GR00T N1)ì„ í•˜ë‚˜ì˜ ì¼ê´€ëœ ì¸í„°í˜ì´ìŠ¤ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆê²Œ í•´ì£¼ëŠ” í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.

## âœ¨ ì£¼ìš” íŠ¹ì§•

- **í†µí•© ì¸í„°í˜ì´ìŠ¤**: ëª¨ë“  ì •ì±… íƒ€ì…ì— ëŒ€í•œ ê³µí†µ `BasePolicy` ì¶”ìƒ í´ë˜ìŠ¤
- **YAML ì„¤ì •**: LeRobotì˜ Python ì„¤ì •ì„ YAMLë¡œ ë³€í™˜í•˜ì—¬ ì‰½ê²Œ í¸ì§‘ ê°€ëŠ¥
- **ì •ì±… íŒ©í† ë¦¬**: ìë™ ì •ì±… ìƒì„± ë° ë“±ë¡ ì‹œìŠ¤í…œ
- **í™•ì¥ ê°€ëŠ¥í•œ êµ¬ì¡°**: ìƒˆë¡œìš´ ì˜¤í”ˆì†ŒìŠ¤ ì •ì±…ì„ ì‰½ê²Œ ì¶”ê°€ ê°€ëŠ¥

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
physical_ai_server/inference/policy/
â”œâ”€â”€ __init__.py                 # íŒ¨í‚¤ì§€ ì´ˆê¸°í™” ë° export
â”œâ”€â”€ base_policy.py              # ì¶”ìƒ ê¸°ë³¸ ì •ì±… ì¸í„°í˜ì´ìŠ¤
â”œâ”€â”€ policy_factory.py           # ì •ì±… íŒ©í† ë¦¬ ë° ì„¤ì • ê´€ë¦¬ì
â”œâ”€â”€ act_policy.py              # ACT ì •ì±… ë˜í¼
â”œâ”€â”€ diffusion_policy.py        # Diffusion ì •ì±… ë˜í¼  
â”œâ”€â”€ pi0_policy.py              # Pi0 ì •ì±… ë˜í¼
â”œâ”€â”€ gr00t_n1_policy.py         # GR00T N1 ì •ì±… ë˜í¼
â”œâ”€â”€ class_diagram.md           # UML í´ë˜ìŠ¤ ë‹¤ì´ì–´ê·¸ë¨
â””â”€â”€ configs/                   # YAML ì„¤ì • íŒŒì¼ í…œí”Œë¦¿
    â”œâ”€â”€ act_config.yaml
    â”œâ”€â”€ diffusion_config.yaml
    â”œâ”€â”€ pi0_config.yaml
    â””â”€â”€ gr00t_n1_config.yaml
```

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1. ê¸°ë³¸ ì‚¬ìš©ë²•

```python
from physical_ai_server.inference.policy import PolicyFactory

# YAML ì„¤ì • íŒŒì¼ë¡œ ì •ì±… ìƒì„±
policy = PolicyFactory.create_policy('act', config_path='configs/act_config.yaml')

# ëª¨ë¸ ë¡œë“œ
policy.load_model()

# ì¶”ë¡  ì‹¤í–‰
observation = {
    'observation.images.top': image_tensor,
    'observation.state': state_tensor
}
action = policy.predict(observation)
```

### 2. ì„¤ì • ë”•ì…”ë„ˆë¦¬ ì‚¬ìš©

```python
config = {
    'policy_type': 'diffusion',
    'device': 'cuda',
    'model': {
        'name': 'DiffusionPolicy',
        'pretrained_policy_name_or_path': 'lerobot/diffusion_pusht'
    }
}

policy = PolicyFactory.create_policy('diffusion', config_dict=config)
```

## ğŸ¤– ì§€ì›ë˜ëŠ” ì •ì±…ë“¤

### 1. ACT (Action Chunking Transformer)
- **ì†ŒìŠ¤**: LeRobot
- **êµ¬ì¡°**: Vision backbone + Transformer + VAE
- **ìš©ë„**: ì–‘ì† ì¡°ì‘, ìˆœì°¨ì  ì•¡ì…˜
- **ì£¼ìš” ê¸°ëŠ¥**: Action chunking, ë³€ë¶„ ì¸ì½”ë”©

### 2. Diffusion Policy
- **ì†ŒìŠ¤**: LeRobot  
- **êµ¬ì¡°**: Vision backbone + U-Net + Noise scheduler
- **ìš©ë„**: ë³µì¡í•œ ì¡°ì‘, ë…¸ì´ì¦ˆ ê²¬ê³  í”Œë˜ë‹
- **ì£¼ìš” ê¸°ëŠ¥**: Denoising diffusion, ë‹¤ë‹¨ê³„ ì˜ˆì¸¡

### 3. Pi0 Policy
- **ì†ŒìŠ¤**: LeRobot
- **êµ¬ì¡°**: PaliGemma VLM + Action projector
- **ìš©ë„**: ì–¸ì–´ ì¡°ê±´ë¶€ ì¡°ì‘
- **ì£¼ìš” ê¸°ëŠ¥**: ë¹„ì „-ì–¸ì–´ ì´í•´, flow matching

### 4. GR00T N1 Policy
- **ì†ŒìŠ¤**: Isaac-GR00T
- **êµ¬ì¡°**: Eagle backbone + Diffusion transformer
- **ìš©ë„**: íœ´ë¨¸ë…¸ì´ë“œ ì œì–´, embodied AI
- **ì£¼ìš” ê¸°ëŠ¥**: ë‹¤ì¤‘ embodiment, ì‹œí€€ìŠ¤ ì²˜ë¦¬

## âš™ï¸ ì„¤ì • ì‹œìŠ¤í…œ

### YAML ì„¤ì • íŒŒì¼ ì˜ˆì‹œ

#### ACT Policy ì„¤ì •
```yaml
# act_config.yaml
policy_type: act
device: cuda

model:
  name: ACTPolicy
  pretrained_policy_name_or_path: lerobot/act_aloha_mobile_base
  revision: main

inference:
  batch_size: 1
  num_inference_steps: 10
```

#### Diffusion Policy ì„¤ì •
```yaml
# diffusion_config.yaml
policy_type: diffusion
device: cuda

model:
  name: DiffusionPolicy
  pretrained_policy_name_or_path: lerobot/diffusion_pusht
  revision: main

inference:
  batch_size: 1
  num_inference_steps: 20
```

#### GR00T N1 ì„¤ì •
```yaml
# gr00t_n1_config.yaml
policy_type: gr00t_n1
device: cuda

model:
  checkpoint_path: "/path/to/gr00t_checkpoint.pt"
  config_path: "/path/to/gr00t_config.yaml"

inference:
  batch_size: 1
  sequence_length: 50
```

## ğŸ› ï¸ API ì‚¬ìš©ë²•

### PolicyFactory í´ë˜ìŠ¤

```python
from physical_ai_server.inference.policy import PolicyFactory

# ì‚¬ìš© ê°€ëŠ¥í•œ ì •ì±…ë“¤ í™•ì¸
available_policies = PolicyFactory.get_available_policies()
print(f"ì‚¬ìš© ê°€ëŠ¥í•œ ì •ì±…ë“¤: {list(available_policies.keys())}")

# ì„¤ì • íŒŒì¼ì—ì„œ ì •ì±… ë¡œë“œ
policy = PolicyFactory.load_from_config_file('configs/act_config.yaml')

# í…œí”Œë¦¿ ì„¤ì • ìƒì„±
template = ConfigManager.create_template_config('diffusion', 'my_diffusion_config.yaml')
```

### BasePolicy ì¸í„°í˜ì´ìŠ¤

ëª¨ë“  ì •ì±…ì´ ìƒì†ë°›ëŠ” ê¸°ë³¸ í´ë˜ìŠ¤ì…ë‹ˆë‹¤:

```python
# í•„ìˆ˜ êµ¬í˜„ ë©”ì„œë“œë“¤
def load_model(self, checkpoint_path: str) -> None:
    """ëª¨ë¸ ë¡œë“œ"""
    pass

def predict(self, observation, **kwargs):
    """ì¶”ë¡  ì‹¤í–‰"""
    pass

def reset(self) -> None:
    """ì •ì±… ìƒíƒœ ë¦¬ì…‹"""
    pass

# ê³µí†µ ìœ í‹¸ë¦¬í‹° ë©”ì„œë“œë“¤
def get_config(self) -> Dict[str, Any]:
    """í˜„ì¬ ì„¤ì • ë°˜í™˜"""

def get_device(self) -> torch.device:
    """í˜„ì¬ ë””ë°”ì´ìŠ¤ ë°˜í™˜"""

def is_model_loaded(self) -> bool:
    """ëª¨ë¸ ë¡œë“œ ìƒíƒœ í™•ì¸"""
```

## ğŸ”§ ìƒˆë¡œìš´ ì •ì±… ì¶”ê°€í•˜ê¸°

### 1. ì •ì±… í´ë˜ìŠ¤ ìƒì„±

```python
from .base_policy import BasePolicy

class MyCustomPolicy(BasePolicy):
    def __init__(self, config_path: str = None, config_dict: Dict[str, Any] = None):
        super().__init__(config_path, config_dict)
        self.policy = None
    
    def load_model(self, checkpoint_path: str = None) -> None:
        # ëª¨ë¸ ë¡œë“œ ë¡œì§ êµ¬í˜„
        pass
        
    def predict(self, observation: Dict[str, Any], **kwargs) -> torch.Tensor:
        # ì¶”ë¡  ë¡œì§ êµ¬í˜„
        pass
        
    def reset(self) -> None:
        # ìƒíƒœ ë¦¬ì…‹ ë¡œì§ êµ¬í˜„
        pass
```

### 2. ì •ì±… ë“±ë¡

```python
# __init__.pyì—ì„œ ë˜ëŠ” ëª¨ë“ˆ ë¡œë“œì‹œ
from .policy_factory import PolicyFactory
PolicyFactory.register_policy('my_custom', MyCustomPolicy)
```

### 3. ì„¤ì • í…œí”Œë¦¿ ì¶”ê°€

`policy_factory.py`ì˜ `ConfigManager.create_template_config`ì— ìƒˆë¡œìš´ ì •ì±… íƒ€ì…ì„ ì¶”ê°€í•©ë‹ˆë‹¤.

## ğŸ“ ì‚¬ìš© ì˜ˆì‹œ

### ê¸°ë³¸ ì¶”ë¡  ì˜ˆì‹œ

```python
import torch
import numpy as np
from physical_ai_server.inference.policy import PolicyFactory

# ACT ì •ì±… ìƒì„± ë° ë¡œë“œ
policy = PolicyFactory.create_policy('act', config_path='configs/act_config.yaml')
policy.load_model()

# ê´€ì¸¡ ë°ì´í„° ì¤€ë¹„
observation = {
    'observation.images.top': torch.randn(3, 224, 224),  # RGB ì´ë¯¸ì§€
    'observation.state': torch.randn(14)  # ë¡œë´‡ ìƒíƒœ
}

# ì¶”ë¡  ì‹¤í–‰
action = policy.predict(observation)
print(f"ì˜ˆì¸¡ëœ ì•¡ì…˜: {action}")

# ì •ì±… ìƒíƒœ ë¦¬ì…‹
policy.reset()
```

### ë‹¤ì¤‘ ì •ì±… ì‚¬ìš©

```python
# ì—¬ëŸ¬ ì •ì±…ì„ ë™ì‹œì— ì‚¬ìš©
policies = {}
policy_types = ['act', 'diffusion', 'pi0']

for policy_type in policy_types:
    config_path = f'configs/{policy_type}_config.yaml'
    policies[policy_type] = PolicyFactory.create_policy(policy_type, config_path=config_path)
    # policies[policy_type].load_model()  # ì‹¤ì œ ëª¨ë¸ ê²½ë¡œ ì„¤ì • í›„ ì£¼ì„ í•´ì œ

# ì•™ìƒë¸” ì¶”ë¡ 
observations = get_observation()  # ì‹¤ì œ ê´€ì¸¡ ë°ì´í„°
ensemble_actions = []

for name, policy in policies.items():
    if policy.is_model_loaded():
        action = policy.predict(observations)
        ensemble_actions.append(action)
        print(f"{name} ì •ì±… ì•¡ì…˜: {action}")
```

### GR00T N1 ì‹œí€€ìŠ¤ ì²˜ë¦¬

```python
# GR00T N1ì˜ ì‹œí€€ìŠ¤ ê¸°ëŠ¥ í™œìš©
gr00t_policy = PolicyFactory.create_policy('gr00t_n1', config_path='configs/gr00t_n1_config.yaml')
# gr00t_policy.load_model()  # ì‹¤ì œ ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ ì„¤ì • í›„ ì‚¬ìš©

# ì‹œí€€ìŠ¤ ê¸¸ì´ ì¡°ì •
gr00t_policy.set_sequence_length(100)

# ì—°ì†ì ì¸ ì¶”ë¡ 
for timestep in range(1000):
    observation = get_observation_at_timestep(timestep)
    action = gr00t_policy.predict(observation)
    execute_action(action)
    
    # ë§¤ 100 ìŠ¤í…ë§ˆë‹¤ ì‹œí€€ìŠ¤ ë²„í¼ í™•ì¸
    if timestep % 100 == 0:
        buffer_info = gr00t_policy.get_sequence_buffer()
        print(f"ì‹œí€€ìŠ¤ ë²„í¼ í¬ê¸°: {len(buffer_info)}")
```

## ğŸ” ì„¤ì • íŒŒì¼ ê´€ë¦¬

### ì„¤ì • ê²€ì¦

```python
from physical_ai_server.inference.policy import ConfigManager

# ì„¤ì • íŒŒì¼ ê²€ì¦
try:
    config = ConfigManager.load_config('configs/act_config.yaml')
    ConfigManager.validate_config(config)
    print("ì„¤ì • íŒŒì¼ì´ ìœ íš¨í•©ë‹ˆë‹¤.")
except ValueError as e:
    print(f"ì„¤ì • ì˜¤ë¥˜: {e}")
```

### í…œí”Œë¦¿ ìƒì„±

```python
# ìƒˆë¡œìš´ ì„¤ì • í…œí”Œë¦¿ ìƒì„±
template = ConfigManager.create_template_config('diffusion', 'my_diffusion_config.yaml')
print("í…œí”Œë¦¿ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")

# ì„¤ì • ìˆ˜ì • í›„ ì €ì¥
template['inference']['num_inference_steps'] = 50
ConfigManager.save_config(template, 'modified_diffusion_config.yaml')
```

## ğŸ› ë¬¸ì œ í•´ê²°

### ì¼ë°˜ì ì¸ ë¬¸ì œë“¤

1. **ImportError**: í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ
   ```bash
   # LeRobot ì„¤ì¹˜
   pip install lerobot
   
   # GR00T ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ (í•„ìš”ì‹œ)
   pip install isaac-sim  # ë˜ëŠ” í•´ë‹¹ íŒ¨í‚¤ì§€
   ```

2. **FileNotFoundError**: ì²´í¬í¬ì¸íŠ¸ë‚˜ ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ
   ```python
   # íŒŒì¼ ê²½ë¡œ í™•ì¸
   import os
   config_path = 'configs/act_config.yaml'
   if os.path.exists(config_path):
       print("ì„¤ì • íŒŒì¼ì´ ì¡´ì¬í•©ë‹ˆë‹¤.")
   else:
       print("ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
   ```

3. **CUDA ë©”ëª¨ë¦¬ ë¶€ì¡±**: GPU ë©”ëª¨ë¦¬ ë¶€ì¡±
   ```yaml
   # ì„¤ì • íŒŒì¼ì—ì„œ ë°°ì¹˜ í¬ê¸° ì¤„ì´ê¸°
   inference:
     batch_size: 1  # ê¸°ë³¸ê°’ì—ì„œ ì¤„ì´ê¸°
   
   # ë˜ëŠ” CPU ëª¨ë“œë¡œ ì „í™˜
   device: cpu
   ```

### ë””ë²„ê¹… ëª¨ë“œ

```python
import logging

# ìì„¸í•œ ë¡œê·¸ í™œì„±í™”
logging.basicConfig(level=logging.DEBUG)

# ì •ì±… ì •ë³´ í™•ì¸
policy = PolicyFactory.create_policy('act')
print(f"ì •ì±… ì •ë³´: {policy.get_model_info()}")

# ì‚¬ìš© ê°€ëŠ¥í•œ ì •ì±…ë“¤ í™•ì¸
available = PolicyFactory.get_available_policies()
print(f"ë“±ë¡ëœ ì •ì±…ë“¤: {list(available.keys())}")
```

## ğŸš€ ê³ ê¸‰ ì‚¬ìš©ë²•

### ì»¤ìŠ¤í…€ ì „ì²˜ë¦¬/í›„ì²˜ë¦¬

```python
class CustomACTPolicy(ACTPolicy):
    def preprocess_observation(self, observation):
        # ì»¤ìŠ¤í…€ ì „ì²˜ë¦¬ ë¡œì§
        processed = super().preprocess_observation(observation)
        
        # ì˜ˆ: ì´ë¯¸ì§€ ì •ê·œí™”
        if 'image' in processed:
            processed['image'] = (processed['image'] - 0.5) / 0.5
        
        return processed
    
    def postprocess_action(self, action):
        # ì»¤ìŠ¤í…€ í›„ì²˜ë¦¬ ë¡œì§
        processed = super().postprocess_action(action)
        
        # ì˜ˆ: ì•¡ì…˜ ìŠ¤ì¼€ì¼ë§
        processed = processed * 2.0
        
        return processed

# ì»¤ìŠ¤í…€ ì •ì±… ë“±ë¡
PolicyFactory.register_policy('custom_act', CustomACTPolicy)
```

### ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™”

```python
# ì—¬ëŸ¬ ê´€ì¸¡ì„ íš¨ìœ¨ì ìœ¼ë¡œ ë°°ì¹˜ ì²˜ë¦¬
observations = [obs1, obs2, obs3]  # ì—¬ëŸ¬ ê´€ì¸¡ ë°ì´í„°

# ë°°ì¹˜ë¡œ ë¬¶ì–´ì„œ ì²˜ë¦¬ (ì •ì±…ì´ ì§€ì›í•˜ëŠ” ê²½ìš°)
if hasattr(policy, 'predict_batch'):
    actions = policy.predict_batch(observations)
else:
    # ê°œë³„ ì²˜ë¦¬
    actions = [policy.predict(obs) for obs in observations]
```

## ğŸ“„ ë¼ì´ì„ ìŠ¤

ì´ í”„ë ˆì„ì›Œí¬ëŠ” ì—¬ëŸ¬ ì˜¤í”ˆì†ŒìŠ¤ í”„ë¡œì íŠ¸ë¥¼ í†µí•©í•©ë‹ˆë‹¤:
- **LeRobot**: Apache 2.0 License
- **GR00T**: Isaac-GR00T ì €ì¥ì†Œì˜ ë¼ì´ì„ ìŠ¤ í™•ì¸
- **Framework Code**: MIT License

## ğŸ™ ê°ì‚¬ì˜ ë§

- **LeRobot íŒ€**: í›Œë¥­í•œ ì •ì±… êµ¬í˜„ë“¤
- **NVIDIA Isaac Lab**: GR00T N1 ì •ì±…
- **Hugging Face**: ê¸°ë°˜ ML ì¸í”„ë¼
- **ì˜¤í”ˆì†ŒìŠ¤ ì»¤ë®¤ë‹ˆí‹°**: ë¡œë³´í‹±ìŠ¤ ì •ì±… ì—°êµ¬

---

## ğŸ—ï¸ ì•„í‚¤í…ì²˜ ë‹¤ì´ì–´ê·¸ë¨

í”„ë ˆì„ì›Œí¬ì˜ ì „ì²´ í´ë˜ìŠ¤ êµ¬ì¡°ëŠ” [`class_diagram.md`](class_diagram.md)ì—ì„œ UML ë‹¤ì´ì–´ê·¸ë¨ìœ¼ë¡œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ë” ë§ì€ ì˜ˆì‹œì™€ ìì„¸í•œ ë¬¸ì„œëŠ” ê° ì •ì±… êµ¬í˜„ íŒŒì¼ì„ ì°¸ì¡°í•˜ì„¸ìš”.
